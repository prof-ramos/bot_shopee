name: Test Automation Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Executar todos os dias Ã s 2h UTC
    - cron: '0 2 * * *'
  workflow_dispatch:

env:
  PYTHON_VERSION: "3.11"

jobs:
  # Job de descoberta e classificaÃ§Ã£o de testes
  discover:
    name: ðŸ“‹ Descobrir Testes
    runs-on: ubuntu-latest
    outputs:
      test-count: ${{ steps.discovery.outputs.count }}
      categories: ${{ steps.discovery.outputs.categories }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -q requests python-dotenv

      - name: Discover tests
        id: discovery
        run: |
          python tests/orchestrator.py --discover 2>&1 | tee test-discovery.txt

  # Job de testes unitÃ¡rios (rÃ¡pidos)
  unit-tests:
    name: ðŸ§ª Testes UnitÃ¡rios
    runs-on: ubuntu-latest
    needs: discover
    strategy:
      matrix:
        # Executar em paralelo em diferentes versÃµes Python
        python-version: ["3.10", "3.11", "3.12"]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -q requests python-dotenv

      - name: Run unit tests
        run: |
          python tests/orchestrator.py \
            --category unit \
            --category mock \
            --parallel \
            --workers 4

      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: unit-results-${{ matrix.python-version }}
          path: test-results.json
          if-no-files-found: 'ignore'

  # Job de testes de integraÃ§Ã£o
  integration-tests:
    name: ðŸ”— Testes de IntegraÃ§Ã£o
    runs-on: ubuntu-latest
    needs: discover
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -q requests python-dotenv

      - name: Run integration tests
        run: |
          python tests/orchestrator.py \
            --category integration \
            --category api \
            --parallel \
            --workers 2
        env:
          SHOPEE_APP_ID: ${{ secrets.SHOPEE_APP_ID }}
          SHOPEE_APP_SECRET: ${{ secrets.SHOPEE_APP_SECRET }}

      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: integration-results
          path: test-results.json
          if-no-files-found: 'ignore'

  # Job de testes completos (CI)
  ci-full:
    name: ðŸš€ CI Completo
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests]
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -q requests python-dotenv

      - name: Run all tests with orchestrator
        run: |
          python tests/orchestrator.py --ci
        env:
          SHOPEE_APP_ID: ${{ secrets.SHOPEE_APP_ID }}
          SHOPEE_APP_SECRET: ${{ secrets.SHOPEE_APP_SECRET }}

      - name: Generate analytics report
        run: |
          python tests/monitoring.py --report --days 7

      - name: Upload results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ci-results
          path: |
            test-results.json
            test_analytics.db
          if-no-files-found: 'ignore'

      - name: Comment PR with results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            try {
              const fs = require('fs');
              const results = JSON.parse(fs.readFileSync('test-results.json', 'utf8'));

              const comment = `## ðŸ“Š Resultados dos Testes

              | Status | Quantidade |
              |--------|-----------|
              | âœ… Passou | ${results.passed} |
              | âŒ Falhou | ${results.failed} |
              | ðŸ’¥ Erros | ${results.errors} |
              | â­ï¸  Pulados | ${results.skipped} |
              | **Total** | **${results.total}** |

              ðŸ“ˆ Taxa de sucesso: **${results.success_rate.toFixed(1)}%**
              â±ï¸  DuraÃ§Ã£o: ${results.duration.toFixed(2)}s
              `;

              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: comment
              });
            } catch (error) {
              if (error.code === 'ENOENT') {
                console.log('âš ï¸ test-results.json nÃ£o encontrado');
              } else {
                console.log('âŒ Erro ao ler arquivo:', error.message);
              }
            }

  # Job de anÃ¡lise de performance
  performance:
    name: âš¡ AnÃ¡lise de Performance
    runs-on: ubuntu-latest
    needs: ci-full
    if: always()
    steps:
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Checkout
        uses: actions/checkout@v4

      - name: Download results
        uses: actions/download-artifact@v4
        with:
          name: ci-results

      - name: Analyze performance
        run: |
          python tests/monitoring.py --optimize --days 7

      - name: Check for flaky tests
        run: |
          python tests/monitoring.py --flaky --days 7 > flaky-report.txt || true

      - name: Check for slow tests
        run: |
          python tests/monitoring.py --slow --days 7 > slow-report.txt || true

      - name: Upload analysis
        uses: actions/upload-artifact@v4
        with:
          name: performance-analysis
          path: |
            flaky-report.txt
            slow-report.txt

  # Job de notificaÃ§Ã£o
  notify:
    name: ðŸ”” Notificar
    runs-on: ubuntu-latest
    needs: [ci-full, performance]
    if: always()
    steps:
      - name: Check test status
        id: check
        run: |
          if [ "${{ needs.ci-full.result }}" == "success" ]; then
            echo "status=success" >> $GITHUB_OUTPUT
            echo "message=âœ… Todos os testes passaram!" >> $GITHUB_OUTPUT
          else
            echo "status=failure" >> $GITHUB_OUTPUT
            echo "message=âŒ Alguns testes falharam" >> $GITHUB_OUTPUT
          fi

      - name: Create status badge
        run: |
          echo "${{ steps.check.outputs.message }}"
          echo "Status: ${{ steps.check.outputs.status }}"
